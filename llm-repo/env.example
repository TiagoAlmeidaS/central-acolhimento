# LLM Service Configuration

# Application
PROJECT_NAME="Central de Acolhimento LLM Service"
VERSION="0.1.0"
DEBUG=false
ENVIRONMENT="development"

# Ollama Configuration
OLLAMA_URL="http://localhost:11434"
OLLAMA_MODEL="llama3:8b"
OLLAMA_TIMEOUT=60
OLLAMA_MAX_RETRIES=3

# MCP Configuration
MCP_PORT=8002
MCP_HOST="0.0.0.0"

# Entity Extraction
EXTRACTION_TIMEOUT=30
MAX_TEXT_LENGTH=2000
MIN_CONFIDENCE=0.7

# CORS
CORS_ORIGINS=["*"]

# Logging
LOG_LEVEL="INFO"
LOG_FORMAT="json"

# Prompt Templates
PROMPT_TEMPLATE_PATH="app/prompt_templates/"
DEFAULT_TEMPLATE="entity_extraction.jinja2"
